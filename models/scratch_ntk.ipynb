{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from time import time\n",
    "from NTK import kernel_value, kernel_value_batch\n",
    "from resampling import NestedCV, BaseModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DATASET_PATH = Path(\"/data/pfizer_tx/tasks_all_clr/all_clr_train_LUAD_stage.h5\")\n",
    "keys = ['/expression', '/labels']\n",
    "test_data = {key : pd.read_hdf(DEFAULT_DATASET_PATH, key = key) for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((542, 57992), (542,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tx = test_data['/expression']\n",
    "Y_tx = test_data['/labels']\n",
    "X_tx.shape, Y_tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 5 \n",
    "C_LIST = [10.0 ** i for i in range(-2, 5)] # hyperparameter for NTK\n",
    "n_classes = len(set(Y_tx)) # n classes\n",
    "n_features = X_tx.shape[1] # n features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg(K_train, K_val, y_train, y_val, C):\n",
    "    clf = SVC(kernel = \"precomputed\", C = C, cache_size = 100000, probability=True)\n",
    "    clf.fit(K_train, y_train)\n",
    "    y_hat = clf.predict_proba(K_val)[:,1]\n",
    "    return roc_auc_score(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate NTK\n",
    "Ks = kernel_value_batch(X_tx, MAX_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [e for e in range(len(Y_tx))]\n",
    "shuffle(idxs)\n",
    "train_fold, val_fold = idxs[:350], idxs[350:]\n",
    "y = Y_tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think train_fold and val_fold are indices for these folds of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and validation set\n",
    "cv_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate kernels and cost values to find the best hyperparameters\n",
    "for depth in range(MAX_DEPTH):\n",
    "    for fix_depth in range(depth + 1):\n",
    "        K = Ks[depth][fix_depth]\n",
    "        for c in C_LIST:\n",
    "            auc = alg(\n",
    "                K_train=K[train_fold][:, train_fold], \n",
    "                K_val=K[val_fold][:, train_fold], \n",
    "                y_train=y[train_fold], \n",
    "                y_val=y[val_fold], \n",
    "                C=c)\n",
    "            key_ = f\"{depth},{fix_depth},{c}\"\n",
    "            try:\n",
    "                cv_results[key_].append(auc)\n",
    "            except KeyError:\n",
    "                cv_results[key_] = [auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results;\n",
    "mean_results = {k : np.mean(v) for k, v in cv_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4,4,100.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = max(mean_results.items(), key=itemgetter(1))[0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTKNestedCV:\n",
    "    def __init__(self, alg, hparams, n_splits_outer=5, n_splits_inner=5, verbose=False):\n",
    "        \"\"\"Nested cross validation class for NTK models only. \n",
    "        Currently only uses AUROC as its performance metric.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alg : func\n",
    "                A function the implements a model that can accept the NTK kernel.  \n",
    "                Currently only SVM works.  \n",
    "                Model selection will be made based on the performance metric that 'alg' returns.  \n",
    "                At present, this is roc_auc_score.  \n",
    "        hparams : dict\n",
    "                A dict containing all the hyperparameters to be tried. \n",
    "                Must contain ['C'] (the list of values for the SVM model)  \n",
    "                and ['max_depth' for the NT kernel.]\n",
    "        n_splits_outer : int\n",
    "                The number of splits in the outer loop\n",
    "        n_splits_inner : int\n",
    "                The number of splits in the inner loop\n",
    "        verbose : bool\n",
    "                If True, prints all the parameter values being tested.\n",
    "                        \n",
    "        \"\"\"\n",
    "        self.alg = alg\n",
    "        self.hparams = hparams\n",
    "        self.n_splits_outer = n_splits_outer\n",
    "        self.n_splits_inner = n_splits_inner\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def _inner_loop(self, input_x, input_y):\n",
    "        \"\"\"The inner x-fold CV loop for finding optimal hyperparameters\"\"\"\n",
    "        inner = KFold(n_splits=self.n_splits_inner)\n",
    "        # instead of an array, we use a dict where the keys are \"<depth>,<fixed_depth>,<C>\" \n",
    "        # and the values are lists to which we can append\n",
    "        inner_fold_results = dict()\n",
    "        Ks = kernel_value_batch(input_x, self.hparams['max_depth'])\n",
    "        \n",
    "        for split_idx, (t, v) in enumerate(inner.split(input_x)):\n",
    "            print(f\"Inner fold {split_idx+1} of {self.n_splits_inner}\")\n",
    "            for depth in range(MAX_DEPTH):\n",
    "                for fix_depth in range(depth + 1):\n",
    "                    K = Ks[depth][fix_depth]\n",
    "                    for c in C_LIST:\n",
    "                        if self.verbose:\n",
    "                            print(f\"Fitting model with depth: {depth}, fix depth: {fix_depth}, C: {c}\")\n",
    "                        auc = self.alg(\n",
    "                            K_train=K[t][:, t], \n",
    "                            K_val=K[v][:, t], \n",
    "                            y_train=y[t], \n",
    "                            y_val=y[v], \n",
    "                            C=c)\n",
    "                        key_ = f\"{depth},{fix_depth},{c}\"\n",
    "                        try:\n",
    "                            inner_fold_results[key_].append(auc)\n",
    "                        except KeyError:\n",
    "                            inner_fold_results[key_] = [auc]\n",
    "\n",
    "        # which hparam combination has best average performance across all splits?\n",
    "        # select these params, train on all the data and return a trained model\n",
    "        mean_results = {k : np.mean(v) for k, v in inner_fold_results.items()}\n",
    "        best_params = max(mean_results.items(), key=itemgetter(1))[0]\n",
    "        best_depth, best_fix, best_C = best_params.split(',')\n",
    "        print(f\"Best params: depth = {best_depth}, fixed depth = {best_fix}, C = {best_C}\")\n",
    "        \n",
    "        return {\"best_depth\" : int(best_depth), \"best_fix\" : int(best_fix), \"best_C\" : float(best_C)}\n",
    "    \n",
    "    def _outer_loop(self, X, Y):\n",
    "        \"\"\"The outer loop that produces an unbiased estimate of large sample performance\"\"\"\n",
    "        start = time()\n",
    "        outer = KFold(n_splits=self.n_splits_outer)\n",
    "        outer_fold_results = dict()\n",
    "        for split_idx, (t, v) in enumerate(outer.split(X)):\n",
    "            print(f\"Outer fold {split_idx+1} of {self.n_splits_outer}\")\n",
    "            x_train, y_train = X.iloc[t], Y.iloc[t]\n",
    "            x_test, y_test = X.iloc[v], Y.iloc[v]\n",
    "            best_params = self._inner_loop(x_train.values, y_train.values)\n",
    "            Ks = kernel_value_batch(X.values, best_params['best_depth']+1)\n",
    "            K = Ks[int(best_params['best_depth'])][int(best_params['best_fix'])]\n",
    "            this_performance = self.alg(\n",
    "                                K_train=K[t][:, t], \n",
    "                                K_val=K[v][:, t], \n",
    "                                y_train=y[t], \n",
    "                                y_val=y[v], \n",
    "                                C=best_params['best_C'])\n",
    "            outer_fold_results[f\"Fold {split_idx+1}\"] = (best_params, this_performance)\n",
    "        time_taken = time() - start\n",
    "        return (outer_fold_results, time_taken)\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        \"\"\"The main train loop for the class. \n",
    "        Takes the full input and output data and returns an array of performance measures (one for each outer loop) and the coresponding model paramaeters\n",
    "        \"\"\"\n",
    "        outer_fold_results, time_taken = self._outer_loop(X, Y)\n",
    "        mean_performance = np.mean([v for p, v in outer_fold_results.values()])\n",
    "        print(f\"Total time taken: {time_taken}\")\n",
    "        print(f\"Mean performance across {self.n_splits_outer} outer splits: {mean_performance}\")\n",
    "        return outer_fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk_nest_cv = NTKNestedCV(alg=alg, hparams={'max_depth' : 5, 'C' : C_LIST}, n_splits_outer=2, n_splits_inner=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1 of 2\n",
      "Inner fold 1 of 2\n",
      "Inner fold 2 of 2\n",
      "Best params: depth = 4, fixed depth = 1, C = 0.01\n",
      "Outer fold 2 of 2\n",
      "Inner fold 1 of 2\n",
      "Inner fold 2 of 2\n",
      "Best params: depth = 4, fixed depth = 0, C = 100.0\n",
      "Total time taken: 5.9234840869903564\n",
      "Mean performance across 2 outer splits: 0.633664282577326\n"
     ]
    }
   ],
   "source": [
    "results = ntk_nest_cv.train(X_tx, Y_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6129720853858784, 0.6539243365330322]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for p, v in results.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTK(BaseModel):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "    def fit(self, X, y):\n",
    "        Ks = kernel_value_batch(X, self.params['max_depth'])\n",
    "        self.best_auc = 0.0\n",
    "        self.best_depth = 0\n",
    "        self.best_fix = 0\n",
    "        self.clf = SVC(kernel = \"precomputed\", C = self.params['C'], cache_size = 100000, probability=True)\n",
    "        for depth in range(self.params['max_depth']):\n",
    "            for fix_depth in range(depth + 1):\n",
    "                K = Ks[depth][fix_depth]\n",
    "                self.clf.fit(K, y)\n",
    "                y_hat = self.clf.predict_proba(K)[:,1]\n",
    "                auc = roc_auc_score(y, y_hat)\n",
    "                if auc > best_auc:\n",
    "                    self.best_auc = auc\n",
    "                    self.best_depth = depth\n",
    "                    self.best_fix = fix_depth\n",
    "        # fit the best model\n",
    "        print (\"Best AUC:\", self.best_auc, \"\\tDepth:\", self.best_depth, \"\\tFix:\", self.best_fix)\n",
    "        K = Ks[self.best_depth][self.best_fix]\n",
    "        self.clf.fit(K, y)\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "        Ks = kernel_value_batch(X, self.params['max_depth'])\n",
    "        K = Ks[self.best_depth][self.best_fix]\n",
    "        y_hat = self.clf.predict_proba(K)[:,1]\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\" : 5, \"C\" : 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NTK(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 1.0 \tDepth: 4 \tFix: 4\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_tx, Y_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(X_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_tx, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
