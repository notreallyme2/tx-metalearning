{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN benchmark\n",
    "\n",
    "This notebook repeats the KNN benchmark reported in [Smith et al.](<https://www.biorxiv.org/content/10.1101/574723v2>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import torch\n",
    "\n",
    "from resampling import NestedCV\n",
    "from utilities import hdf_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/data/pfizer_tx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark classification tasks only. Save filenames for specifc classes of task as .csv files to make life easier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tcga_classification_strings = ['stage', 'grade']\n",
    "# sra_classification_strings = ['GSE']\n",
    "# all_tcga_files = [f for f in os.listdir(DATA_PATH/\"tasks_all_clr\")\\\n",
    "#                             if any([e in f for e in tcga_classification_strings])]\n",
    "# all_sra_files = [f for f in os.listdir(DATA_PATH/\"tasks_all_clr\")\\\n",
    "#                             if any([e in f for e in sra_classification_strings])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(all_tcga_files, columns=[\"filename\"]).to_csv(\"tcga_classification_tasks.csv\", index=False)\n",
    "# pd.DataFrame(all_sra_files, columns=[\"filename\"]).to_csv(\"sra_classification_tasks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_classification_tasks = pd.read_csv(\"tcga_classification_tasks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "best_params = []\n",
    "hparams = dict()\n",
    "hparams['k'] = [1, 3, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on all_clr_train_LUAD_stage.h5\n",
      "Number of inner splits (product of all hparam values): 5\n",
      "Fold 1\n",
      "Fitting model with params: {'k': 1}\n",
      "Fitting model with params: {'k': 3}\n",
      "Fitting model with params: {'k': 5}\n",
      "Fitting model with params: {'k': 7}\n",
      "Fitting model with params: {'k': 9}\n",
      "Best params: {'k': 5}, training final model\n",
      "Fold 2\n",
      "Fitting model with params: {'k': 1}\n",
      "Fitting model with params: {'k': 3}\n",
      "Fitting model with params: {'k': 5}\n",
      "Fitting model with params: {'k': 7}\n",
      "Fitting model with params: {'k': 9}\n",
      "Best params: {'k': 3}, training final model\n",
      "Fold 3\n",
      "Fitting model with params: {'k': 1}\n",
      "Fitting model with params: {'k': 3}\n",
      "Fitting model with params: {'k': 5}\n",
      "Fitting model with params: {'k': 7}\n",
      "Fitting model with params: {'k': 9}\n",
      "Best params: {'k': 7}, training final model\n",
      "Fold 4\n",
      "Fitting model with params: {'k': 1}\n",
      "Fitting model with params: {'k': 3}\n",
      "Fitting model with params: {'k': 5}\n"
     ]
    }
   ],
   "source": [
    "for f in tcga_classification_tasks['filename']:\n",
    "    print(f\"Training on {f}\")\n",
    "    dataset_path = DATA_PATH/\"tasks_all_clr\"/f\n",
    "    keys = hdf_keys(dataset_path)\n",
    "    test_data = {key : pd.read_hdf(dataset_path, key = key) for key in keys}\n",
    "    def model(params):\n",
    "        return KNN(n_neighbors=params['k'], n_jobs=-1)\n",
    "    nestedCV = NestedCV(model, hparams)\n",
    "    performance, params = nestedCV.train(test_data['/expression'], test_data['/labels'])\n",
    "    final_performance = np.mean(performance)\n",
    "    print(f\"Final average model performance: {final_performance}\")\n",
    "    results.append(final_performance)\n",
    "    best_params.append(params)\n",
    "pd.DataFrame(results, columns=[\"results\"]).to_csv(\"tcga_classification_tasks_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
